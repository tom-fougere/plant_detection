{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import random\n",
    "from shutil import copyfile\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ae_models import *\n",
    "from manage_dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "HEIGHT = 64\n",
    "WIDTH = 64\n",
    "BATCH_SIZE = 10\n",
    "SPLIT_RATIO = 0.9\n",
    "TARGET_SIZE = (HEIGHT, WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip file\n",
    "import tarfile\n",
    "\n",
    "filename = 'dataset/synthetic_sugarbeet_random_weeds'\n",
    "\n",
    "# my_tar = tarfile.open(filename + '.tar.gz')\n",
    "# my_tar.extractall('dataset')\n",
    "# my_tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trained images: 1126\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "FOLDER_IMAGES = \"dataset/synthetic_sugarbeet_random_weeds/rgb/\"\n",
    "FOLDER_MASKS = \"dataset/synthetic_sugarbeet_random_weeds/gt/\"\n",
    "TARGET_FOLDER = \"dataset/synthetic_sugarbeet_random_weeds/train_test/\"\n",
    "\n",
    "NB_TRAINED_IMAGES = split_data(FOLDER_IMAGES, FOLDER_MASKS, TARGET_FOLDER, SPLIT_RATIO)\n",
    "print('Number of trained images:', NB_TRAINED_IMAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0, 1.0, 2.0}\n",
      "{0.0, 1.0, 2.0}\n",
      "{0.0, 1.0, 2.0}\n"
     ]
    }
   ],
   "source": [
    "# Understand how the mask is made\n",
    "mask_path = \"dataset/synthetic_sugarbeet_random_weeds/gt/\"\n",
    "list_masks = os.listdir(mask_path)\n",
    "\n",
    "masks_layer1 = []\n",
    "masks_layer2 = []\n",
    "masks_layer3 = []\n",
    "for i in range(5):\n",
    "    current_mask = cv2.imread(mask_path + list_masks[i])\n",
    "    masks_layer1 = np.concatenate([masks_layer1, current_mask[:,:,0].flatten()])\n",
    "    masks_layer2 = np.concatenate([masks_layer1, current_mask[:,:,1].flatten()])\n",
    "    masks_layer3 = np.concatenate([masks_layer1, current_mask[:,:,2].flatten()])\n",
    "    \n",
    "print(set(masks_layer1))\n",
    "print(set(masks_layer2))\n",
    "print(set(masks_layer3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot masks\n",
    "mask_path = \"dataset/synthetic_sugarbeet_random_weeds/gt/\"\n",
    "list_masks = os.listdir(mask_path)\n",
    "\n",
    "for i in range(3):\n",
    "    current_mask = cv2.imread(mask_path + list_masks[i])\n",
    "    current_mask = current_mask*100\n",
    "    layers = np.concatenate((current_mask[:,:,0], current_mask[:,:,1], current_mask[:,:,2]), axis=1)\n",
    "    \n",
    "    if i > 0:\n",
    "        images = np.concatenate((images, layers), axis=0)\n",
    "    else:\n",
    "        images = layers            \n",
    "\n",
    "# Plot image\n",
    "cv2.imshow('Example', images) \n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing of images and masks\n",
    "def preprocessing_masks(mask):\n",
    "    img = mask > 0\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    return img    \n",
    "\n",
    "def preprocessing_images(image):\n",
    "    img = image.astype(np.float32)\n",
    "    img = cv2.resize(image, (TARGET_SIZE[1], TARGET_SIZE[0]))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img / 255.    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post processing of images and masks for visualization\n",
    "def postprocessing_masks_rgb(mask, new_size=TARGET_SIZE):\n",
    "    img = mask>0\n",
    "    img = img * 255\n",
    "    img = img.astype(np.uint8)\n",
    "    img = cv2.resize(img, (new_size[1], new_size[0]))\n",
    "    return img\n",
    "\n",
    "def postprocessing_masks_prediction(mask, new_size=TARGET_SIZE):\n",
    "    img = np.zeros(shape=(mask.shape[0], mask.shape[1], 3))\n",
    "    img[:,:,0] = img[:,:,1] = img[:,:,2]= mask[:,:,0]\n",
    "    img = img * 255\n",
    "    img = img.astype(np.uint8)\n",
    "    img = cv2.resize(img, (new_size[1], new_size[0]))\n",
    "    return img\n",
    "\n",
    "def postprocessing_images(image, new_size=TARGET_SIZE):\n",
    "    img = cv2.resize(image, (new_size[1], new_size[0]))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot an image with its mask\n",
    "def plot_image_with_mask(image, mask):    \n",
    "    mask_norm = postprocessing_masks_rgb(mask, image.shape)\n",
    "        \n",
    "    mixed_image = cv2.addWeighted(image, 0.5, mask_norm, 0.5, 0)      \n",
    "    raw_images = np.concatenate((image, mask_norm), axis=1)\n",
    "    example = np.concatenate((raw_images, mixed_image), axis=1)\n",
    "    \n",
    "    # Plot image\n",
    "    cv2.imshow('Example', example) \n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 1126\n",
      "Selected image: 0\n",
      "70\n",
      "133\n",
      "172\n"
     ]
    }
   ],
   "source": [
    "list_files = os.listdir(TARGET_FOLDER + 'train/images/img/')\n",
    "print('Number of images:', len(list_files))\n",
    "IMG_ID = 0\n",
    "print('Selected image:', IMG_ID)\n",
    "\n",
    "example_image = cv2.imread(TARGET_FOLDER + 'train/images/img/' + list_files[IMG_ID])\n",
    "example_mask = cv2.imread(TARGET_FOLDER + 'train/masks/img/' + list_files[IMG_ID])\n",
    "\n",
    "print(np.max(example_image[:,:,0]))\n",
    "print(np.max(example_image[:,:,1]))\n",
    "print(np.max(example_image[:,:,2]))\n",
    "\n",
    "plot_image_with_mask(example_image, example_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1126 images belonging to 1 classes.\n",
      "Found 1126 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation (for train dataset)\n",
    "SEED = 0\n",
    "\n",
    "train_image_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1/255.,\n",
    "                                                                horizontal_flip=True,\n",
    "                                                                rotation_range=20,\n",
    "                                                                zoom_range=0.2,\n",
    "                                                                width_shift_range = 0.1,\n",
    "                                                                height_shift_range = 0.1)\n",
    "train_image_generator = train_image_datagen.flow_from_directory(TARGET_FOLDER + 'train/images',\n",
    "                                                               batch_size=BATCH_SIZE,\n",
    "                                                               target_size=TARGET_SIZE,\n",
    "                                                               color_mode='rgb',\n",
    "                                                               class_mode=None,\n",
    "                                                               seed=SEED)\n",
    "\n",
    "train_mask_datagen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocessing_masks,\n",
    "                                                                horizontal_flip=True,\n",
    "                                                                rotation_range=20,\n",
    "                                                                zoom_range=0.2,\n",
    "                                                                width_shift_range = 0.1,\n",
    "                                                                height_shift_range = 0.1)\n",
    "train_mask_generator = train_mask_datagen.flow_from_directory(TARGET_FOLDER + 'train/masks/',\n",
    "                                                               batch_size=BATCH_SIZE,\n",
    "                                                               target_size=TARGET_SIZE,\n",
    "                                                               color_mode='grayscale',\n",
    "                                                               class_mode=None,\n",
    "                                                               seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 126 images belonging to 1 classes.\n",
      "Found 126 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation (for validation dataset)\n",
    "SEED = 1\n",
    "\n",
    "val_image_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1/255.)\n",
    "val_image_generator= val_image_datagen.flow_from_directory(TARGET_FOLDER + 'test/images',\n",
    "                                                               batch_size=BATCH_SIZE,\n",
    "                                                               target_size=TARGET_SIZE,\n",
    "                                                               class_mode=None,\n",
    "                                                               seed=SEED)\n",
    "\n",
    "val_mask_datagen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocessing_masks)\n",
    "val_mask_generator= val_image_datagen.flow_from_directory(TARGET_FOLDER + 'test/masks/',\n",
    "                                                               batch_size=BATCH_SIZE,\n",
    "                                                               target_size=TARGET_SIZE,\n",
    "                                                               class_mode=None,\n",
    "                                                               seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom generator for training images and masks\n",
    "def my_image_mask_generator(image_data_generator, mask_data_generator):\n",
    "    train_generator = zip(image_data_generator, mask_data_generator)\n",
    "    for (img, mask) in train_generator:\n",
    "        yield (img, mask, [None])\n",
    "        \n",
    "my_train_generator = my_image_mask_generator(train_image_generator, train_mask_generator)\n",
    "my_val_generator = my_image_mask_generator(val_image_generator, val_mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 64, 64, 3)\n",
      "(10, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "# Display one couple image/mask from generators\n",
    "for (img, mask, trash) in my_train_generator:\n",
    "        \n",
    "    # Image\n",
    "    cur_image = img[0]*255\n",
    "    cur_image = cur_image.astype(np.uint8)\n",
    "    cur_image = cv2.cvtColor(cur_image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Mask    \n",
    "    cur_mask = np.zeros(shape=cur_image.shape)\n",
    "    cur_mask[:,:,0] = cur_mask[:,:,1] = cur_mask[:,:,2] = mask[0][:,:,0] * 255.\n",
    "    \n",
    "    # Create concatenation\n",
    "    image_mask = np.concatenate((cur_image, cur_mask), axis=1)\n",
    "    image_mask = image_mask.astype(np.uint8)\n",
    "\n",
    "    # Plot image\n",
    "    cv2.imshow('Example from generator', image_mask) \n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the encoder using the default input size 64 x 84\n",
    "convs, img_input = FCN8()\n",
    "\n",
    "# pass the convolutions obtained in the encoder to the decoder\n",
    "n_classes = 1\n",
    "dec_op = fcn8_decoder(convs, n_classes)\n",
    "\n",
    "print(dec_op.shape)\n",
    "\n",
    "# define the model specifying the input (batch of images) and output (decoder output)\n",
    "model = tf.keras.Model(inputs = img_input, outputs = dec_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile your model here\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "steps = NB_TRAINED_IMAGES / BATCH_SIZE\n",
    "steps = 5000 / BATCH_SIZE\n",
    "print('Steps:', steps)\n",
    "\n",
    "# Train your model here\n",
    "history = model.fit(my_train_generator,\n",
    "                    steps_per_epoch=steps,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_data=my_val_generator,\n",
    "                    validation_steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot one prediction\n",
    "IMG_ID = 6\n",
    "pathname = 'train/images/img/'\n",
    "list_files = os.listdir(TARGET_FOLDER + pathname)\n",
    "\n",
    "example_image = cv2.imread(TARGET_FOLDER + 'train/images/img/' + list_files[IMG_ID])\n",
    "example_mask = cv2.imread(TARGET_FOLDER + 'train/masks/img/' + list_files[IMG_ID])\n",
    "\n",
    "image_processed = preprocessing_images(example_image)\n",
    "image_processed = tf.expand_dims(image_processed, axis=0)\n",
    "\n",
    "prediction = model.predict(image_processed)\n",
    "pred_image = np.array(tf.squeeze(prediction, axis=0))\n",
    "\n",
    "image_example_gt = np.concatenate((postprocessing_images(example_image),\n",
    "                                   postprocessing_masks_rgb(example_mask),\n",
    "                                   postprocessing_masks_prediction(pred_image)), axis=1)\n",
    "cv2.imshow('Example', image_example_gt) \n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT LOSS AND ACCURACY\n",
    "#-----------------------------------------------------------\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "#-----------------------------------------------------------\n",
    "acc=history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs=range(len(acc)) # Get number of epochs\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation accuracy per epoch\n",
    "#------------------------------------------------\n",
    "plt.figure()\n",
    "plt.plot(epochs, acc, 'r')\n",
    "plt.plot(epochs, val_acc, 'b')\n",
    "plt.legend([\"Training\", \"Validation\"])\n",
    "plt.title('Accuracy')\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation loss per epoch\n",
    "#------------------------------------------------\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'r')\n",
    "plt.plot(epochs, val_loss, 'b')\n",
    "plt.legend([\"Training\", \"Validation\"])\n",
    "plt.title('Loss')\n",
    "\n",
    "# Desired output. Charts with training and validation metrics. No crash :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_wise_metrics(y_true, y_pred):\n",
    "  '''\n",
    "  Computes the class-wise IOU and Dice Score.\n",
    "\n",
    "  Args:\n",
    "    y_true (tensor) - ground truth label maps\n",
    "    y_pred (tensor) - predicted label maps\n",
    "  '''\n",
    "  class_wise_iou = []\n",
    "  class_wise_dice_score = []\n",
    "\n",
    "  smoothing_factor = 0.00001\n",
    "\n",
    "  for i in range(n_classes):\n",
    "    intersection = np.sum((y_pred == i) * (y_true == i))\n",
    "    y_true_area = np.sum((y_true == i))\n",
    "    y_pred_area = np.sum((y_pred == i))\n",
    "    combined_area = y_true_area + y_pred_area\n",
    "    \n",
    "    iou = (intersection) / (combined_area - intersection + smoothing_factor)\n",
    "    class_wise_iou.append(iou)\n",
    "    \n",
    "    dice_score =  2 * ((intersection) / (combined_area + smoothing_factor))\n",
    "    class_wise_dice_score.append(dice_score)\n",
    "\n",
    "  return class_wise_iou, class_wise_dice_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_wise_iou, class_wise_dice_score = class_wise_metrics(postprocessing_masks_rgb(example_mask), postprocessing_masks_prediction(pred_image))\n",
    "print(class_wise_iou)\n",
    "print(class_wise_dice_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (img, mask) in my_val_generator:\n",
    "    \n",
    "    average_iou = 0.\n",
    "    average_dice = 0.\n",
    "    count = 0.\n",
    "    for cur_img, cur_mask in zip(img, mask):\n",
    "        count += 1\n",
    "        \n",
    "        # Compute prediction\n",
    "        tensor_img = np.expand_dims(cur_img, axis=0)\n",
    "        result = model.predict(tensor_img)\n",
    "        \n",
    "        # Compute performance\n",
    "        cls_wise_iou, cls_wise_dice_score = class_wise_metrics(cur_mask, postprocessing_masks_prediction(result[0]))        \n",
    "        \n",
    "        average_iou += cls_wise_iou[0]\n",
    "        average_dice += cls_wise_dice_score[0]\n",
    "    \n",
    "    average_iou = average_iou / count\n",
    "    average_dice = average_dice / count\n",
    "    \n",
    "    break\n",
    "\n",
    "print('Average IoU:', average_iou*100)\n",
    "print('Average Dice:', average_dice*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
