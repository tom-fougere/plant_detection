{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import random\n",
    "from shutil import copyfile\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ae_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "HEIGHT = 64\n",
    "WIDTH = 64\n",
    "BATCH_SIZE = 10\n",
    "SPLIT_RATIO = 0.9\n",
    "TARGET_SIZE = (HEIGHT, WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip file\n",
    "import tarfile\n",
    "\n",
    "filename = 'dataset/synthetic_sugarbeet_random_weeds'\n",
    "\n",
    "# my_tar = tarfile.open(filename + '.tar.gz')\n",
    "# my_tar.extractall('dataset')\n",
    "# my_tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create all directories from a string path\n",
    "def make_directory(fullpath):\n",
    "    splitted_data = fullpath.split('/')\n",
    "    \n",
    "    new_dir = []\n",
    "    current_dir = '.'\n",
    "    \n",
    "    for folder in splitted_data:           \n",
    "        current_dir = current_dir + '/' + folder                \n",
    "        if not os.path.isdir(current_dir + '/'):\n",
    "            new_dir.append(current_dir)\n",
    "            os.mkdir(current_dir)\n",
    "    \n",
    "    return new_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a python function called split_data which takes\n",
    "# a FOLDER_IMAGES directory containing the images\n",
    "# a FOLDER_MASKS directory containing the masks\n",
    "# a TARGET_FOLDER directory where the files will be copied to\n",
    "# the TARGET_FOLDER directory will contain 2 subfolders train and test with the data splitted\n",
    "# a SPLIT SIZE to determine the portion\n",
    "# The files should also be randomized, so that the training set is a random\n",
    "# X% of the files, and the test set is the remaining files\n",
    "# SO, for example, if SPLIT SIZE is .9\n",
    "# Then 90% of the images will be copied to the TARGET_FOLDER/train dir\n",
    "# and 10% of the images will be copied to the TARGET_FOLDER/test dir\n",
    "# Also -- All images should be checked, and if they have a zero file length,\n",
    "# they will not be copied over\n",
    "def split_data(FOLDER_IMAGES, FOLDER_MASKS, TARGET_FOLDER, SPLIT_SIZE):\n",
    "\n",
    "    TRAINING_FOLDER_NAME = TARGET_FOLDER + '/train/'\n",
    "    TESTING_FOLDER_NAME = TARGET_FOLDER + '/test/'\n",
    "    TRAINING_FOLDER_NAME_IMAGES = TARGET_FOLDER + '/train/images/img/'\n",
    "    TRAINING_FOLDER_NAME_MASKS = TARGET_FOLDER + '/train/masks/img/'\n",
    "    TESTING_FOLDER_NAME_IMAGES = TARGET_FOLDER + '/test/images/img/'\n",
    "    TESTING_FOLDER_NAME_MASKS = TARGET_FOLDER + '/test/masks/img/'\n",
    "\n",
    "    # Create directories\n",
    "    make_directory(TRAINING_FOLDER_NAME_IMAGES)\n",
    "    make_directory(TRAINING_FOLDER_NAME_MASKS)\n",
    "    make_directory(TESTING_FOLDER_NAME_IMAGES)\n",
    "    make_directory(TESTING_FOLDER_NAME_MASKS)\n",
    "    \n",
    "    # Remove all data in TRAINING and TESTING dir\n",
    "    for i_file in os.listdir(TRAINING_FOLDER_NAME_IMAGES):\n",
    "        os.remove(TRAINING_FOLDER_NAME_IMAGES + i_file)\n",
    "    for i_file in os.listdir(TRAINING_FOLDER_NAME_MASKS):\n",
    "        os.remove(TRAINING_FOLDER_NAME_MASKS + i_file)\n",
    "    for i_file in os.listdir(TESTING_FOLDER_NAME_IMAGES):\n",
    "        os.remove(TESTING_FOLDER_NAME_IMAGES + i_file)\n",
    "    for i_file in os.listdir(TESTING_FOLDER_NAME_MASKS):\n",
    "        os.remove(TESTING_FOLDER_NAME_MASKS + i_file)\n",
    "    \n",
    "    dataset = []\n",
    "    \n",
    "    # Check for z zero file length\n",
    "    for i_file in os.listdir(FOLDER_IMAGES):\n",
    "        data = i_file\n",
    "        if (os.path.getsize(FOLDER_IMAGES + data) > 0):\n",
    "            dataset.append(i_file)\n",
    "        else:\n",
    "            print('Skipped ' + i_file)\n",
    "            print('Invalid file size! i.e Zero length.')\n",
    "    \n",
    "    # Number of files\n",
    "    nb_files = len(dataset)\n",
    "    nb_files_training = int(nb_files * SPLIT_SIZE)\n",
    "    nb_files_testing = nb_files - nb_files_training\n",
    "    \n",
    "    # Suffle dataset\n",
    "    shuffled_dataset = random.sample(dataset, len(dataset))\n",
    "        \n",
    "    # Copy files\n",
    "    for i_num, i_file in enumerate(shuffled_dataset):\n",
    "        if i_num < nb_files_training:\n",
    "            new_path_images = TRAINING_FOLDER_NAME_IMAGES + i_file\n",
    "            new_path_masks = TRAINING_FOLDER_NAME_MASKS + i_file\n",
    "        else:\n",
    "            new_path_images = TESTING_FOLDER_NAME_IMAGES + i_file\n",
    "            new_path_masks = TESTING_FOLDER_NAME_MASKS + i_file\n",
    "            \n",
    "        copyfile(FOLDER_IMAGES + i_file, new_path_images)\n",
    "        copyfile(FOLDER_MASKS + i_file, new_path_masks)\n",
    "        \n",
    "    return nb_files_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trained images: 1126\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "FOLDER_IMAGES = \"dataset/synthetic_sugarbeet_random_weeds/rgb/\"\n",
    "FOLDER_MASKS = \"dataset/synthetic_sugarbeet_random_weeds/gt/\"\n",
    "TARGET_FOLDER = \"dataset/synthetic_sugarbeet_random_weeds/train_test/\"\n",
    "\n",
    "NB_TRAINED_IMAGES = split_data(FOLDER_IMAGES, FOLDER_MASKS, TARGET_FOLDER, SPLIT_RATIO)\n",
    "print('Number of trained images:', NB_TRAINED_IMAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0, 1.0, 2.0}\n",
      "{0.0, 1.0, 2.0}\n",
      "{0.0, 1.0, 2.0}\n"
     ]
    }
   ],
   "source": [
    "# Understand how the mask is made\n",
    "mask_path = \"dataset/synthetic_sugarbeet_random_weeds/gt/\"\n",
    "list_masks = os.listdir(mask_path)\n",
    "\n",
    "masks_layer1 = []\n",
    "masks_layer2 = []\n",
    "masks_layer3 = []\n",
    "for i in range(5):\n",
    "    current_mask = cv2.imread(mask_path + list_masks[i])\n",
    "    masks_layer1 = np.concatenate([masks_layer1, current_mask[:,:,0].flatten()])\n",
    "    masks_layer2 = np.concatenate([masks_layer1, current_mask[:,:,1].flatten()])\n",
    "    masks_layer3 = np.concatenate([masks_layer1, current_mask[:,:,2].flatten()])\n",
    "    \n",
    "print(set(masks_layer1))\n",
    "print(set(masks_layer2))\n",
    "print(set(masks_layer3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot masks\n",
    "mask_path = \"dataset/synthetic_sugarbeet_random_weeds/gt/\"\n",
    "list_masks = os.listdir(mask_path)\n",
    "\n",
    "for i in range(3):\n",
    "    current_mask = cv2.imread(mask_path + list_masks[i])\n",
    "    current_mask = current_mask*100\n",
    "    layers = np.concatenate((current_mask[:,:,0], current_mask[:,:,1], current_mask[:,:,2]), axis=1)\n",
    "    \n",
    "    if i > 0:\n",
    "        images = np.concatenate((images, layers), axis=0)\n",
    "    else:\n",
    "        images = layers            \n",
    "\n",
    "# Plot image\n",
    "cv2.imshow('Example', images) \n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing of images and masks\n",
    "def preprocessing_masks(mask):\n",
    "    img = mask > 0\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    return img    \n",
    "\n",
    "def preprocessing_images(image):\n",
    "    img = image.astype(np.float32)\n",
    "    img = cv2.resize(image, (TARGET_SIZE[1], TARGET_SIZE[0]))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img / 255.    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post processing of images and masks for visualization\n",
    "def postprocessing_masks_rgb(mask, new_size=TARGET_SIZE):\n",
    "    img = mask>0\n",
    "    img = img * 255\n",
    "    img = img.astype(np.uint8)\n",
    "    img = cv2.resize(img, (new_size[1], new_size[0]))\n",
    "    return img\n",
    "\n",
    "def postprocessing_masks_prediction(mask, new_size=TARGET_SIZE):\n",
    "    img = np.zeros(shape=(mask.shape[0], mask.shape[1], 3))\n",
    "    img[:,:,0] = img[:,:,1] = img[:,:,2]= mask[:,:,0]\n",
    "    img = img * 255\n",
    "    img = img.astype(np.uint8)\n",
    "    img = cv2.resize(img, (new_size[1], new_size[0]))\n",
    "    return img\n",
    "\n",
    "def postprocessing_images(image, new_size=TARGET_SIZE):\n",
    "    img = cv2.resize(image, (new_size[1], new_size[0]))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot an image with its mask\n",
    "def plot_image_with_mask(image, mask):    \n",
    "    mask_norm = postprocessing_masks_rgb(mask, image.shape)\n",
    "        \n",
    "    mixed_image = cv2.addWeighted(image, 0.5, mask_norm, 0.5, 0)      \n",
    "    raw_images = np.concatenate((image, mask_norm), axis=1)\n",
    "    example = np.concatenate((raw_images, mixed_image), axis=1)\n",
    "    \n",
    "    # Plot image\n",
    "    cv2.imshow('Example', example) \n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 1126\n",
      "Selected image: 0\n",
      "70\n",
      "133\n",
      "172\n"
     ]
    }
   ],
   "source": [
    "list_files = os.listdir(TARGET_FOLDER + 'train/images/img/')\n",
    "print('Number of images:', len(list_files))\n",
    "IMG_ID = 0\n",
    "print('Selected image:', IMG_ID)\n",
    "\n",
    "example_image = cv2.imread(TARGET_FOLDER + 'train/images/img/' + list_files[IMG_ID])\n",
    "example_mask = cv2.imread(TARGET_FOLDER + 'train/masks/img/' + list_files[IMG_ID])\n",
    "\n",
    "print(np.max(example_image[:,:,0]))\n",
    "print(np.max(example_image[:,:,1]))\n",
    "print(np.max(example_image[:,:,2]))\n",
    "\n",
    "plot_image_with_mask(example_image, example_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1126 images belonging to 1 classes.\n",
      "Found 1126 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation (for train dataset)\n",
    "SEED = 0\n",
    "\n",
    "train_image_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1/255.,\n",
    "                                                                horizontal_flip=True,\n",
    "                                                                rotation_range=20,\n",
    "                                                                zoom_range=0.2,\n",
    "                                                                width_shift_range = 0.1,\n",
    "                                                                height_shift_range = 0.1)\n",
    "train_image_generator = train_image_datagen.flow_from_directory(TARGET_FOLDER + 'train/images',\n",
    "                                                               batch_size=BATCH_SIZE,\n",
    "                                                               target_size=TARGET_SIZE,\n",
    "                                                               color_mode='rgb',\n",
    "                                                               class_mode=None,\n",
    "                                                               seed=SEED)\n",
    "\n",
    "train_mask_datagen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocessing_masks,\n",
    "                                                                horizontal_flip=True,\n",
    "                                                                rotation_range=20,\n",
    "                                                                zoom_range=0.2,\n",
    "                                                                width_shift_range = 0.1,\n",
    "                                                                height_shift_range = 0.1)\n",
    "train_mask_generator = train_mask_datagen.flow_from_directory(TARGET_FOLDER + 'train/masks/',\n",
    "                                                               batch_size=BATCH_SIZE,\n",
    "                                                               target_size=TARGET_SIZE,\n",
    "                                                               color_mode='grayscale',\n",
    "                                                               class_mode=None,\n",
    "                                                               seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 126 images belonging to 1 classes.\n",
      "Found 126 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation (for validation dataset)\n",
    "SEED = 1\n",
    "\n",
    "val_image_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1/255.)\n",
    "val_image_generator= val_image_datagen.flow_from_directory(TARGET_FOLDER + 'test/images',\n",
    "                                                               batch_size=BATCH_SIZE,\n",
    "                                                               target_size=TARGET_SIZE,\n",
    "                                                               class_mode=None,\n",
    "                                                               seed=SEED)\n",
    "\n",
    "val_mask_datagen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocessing_masks)\n",
    "val_mask_generator= val_image_datagen.flow_from_directory(TARGET_FOLDER + 'test/masks/',\n",
    "                                                               batch_size=BATCH_SIZE,\n",
    "                                                               target_size=TARGET_SIZE,\n",
    "                                                               class_mode=None,\n",
    "                                                               seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom generator for training images and masks\n",
    "def my_image_mask_generator(image_data_generator, mask_data_generator):\n",
    "    train_generator = zip(image_data_generator, mask_data_generator)\n",
    "    for (img, mask) in train_generator:\n",
    "        yield (img, mask, [None])\n",
    "        \n",
    "my_train_generator = my_image_mask_generator(train_image_generator, train_mask_generator)\n",
    "my_val_generator = my_image_mask_generator(val_image_generator, val_mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display one couple image/mask from generators\n",
    "for (img, mask) in my_train_generator:\n",
    "        \n",
    "    # Image\n",
    "    cur_image = img[0]*255\n",
    "    cur_image = cur_image.astype(np.uint8)\n",
    "    cur_image = cv2.cvtColor(cur_image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Mask    \n",
    "    cur_mask = np.zeros(shape=cur_image.shape)\n",
    "    cur_mask[:,:,0] = cur_mask[:,:,1] = cur_mask[:,:,2] = mask[0][:,:,0] * 255.\n",
    "    \n",
    "    # Create concatenation\n",
    "    image_mask = np.concatenate((cur_image, cur_mask), axis=1)\n",
    "    image_mask = image_mask.astype(np.uint8)\n",
    "\n",
    "    # Plot image\n",
    "    cv2.imshow('Example from generator', image_mask) \n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "# start the encoder using the default input size 64 x 84\n",
    "convs, img_input = FCN8()\n",
    "\n",
    "# pass the convolutions obtained in the encoder to the decoder\n",
    "n_classes = 1\n",
    "dec_op = fcn8_decoder(convs, n_classes)\n",
    "\n",
    "print(dec_op.shape)\n",
    "\n",
    "# define the model specifying the input (batch of images) and output (decoder output)\n",
    "model = tf.keras.Model(inputs = img_input, outputs = dec_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 500.0\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 500.0 steps, validate for 500.0 steps\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 501s 1s/step - loss: 0.6862 - accuracy: 0.5289 - val_loss: 0.6835 - val_accuracy: 0.5263\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 465s 930ms/step - loss: 0.5702 - accuracy: 0.6507 - val_loss: 0.5173 - val_accuracy: 0.6722\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 473s 946ms/step - loss: 0.3116 - accuracy: 0.8641 - val_loss: 0.2747 - val_accuracy: 0.9043\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 466s 932ms/step - loss: 0.1682 - accuracy: 0.9549 - val_loss: 0.1935 - val_accuracy: 0.9334\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 465s 931ms/step - loss: 0.1211 - accuracy: 0.9655 - val_loss: 0.1418 - val_accuracy: 0.9387\n"
     ]
    }
   ],
   "source": [
    "# Compile your model here\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "steps = NB_TRAINED_IMAGES / BATCH_SIZE\n",
    "steps = 5000 / BATCH_SIZE\n",
    "print('Steps:', steps)\n",
    "\n",
    "# Train your model here\n",
    "history = model.fit(my_train_generator,\n",
    "                    steps_per_epoch=steps,\n",
    "                    epochs=5,\n",
    "                    verbose=1,\n",
    "                    validation_data=my_val_generator,\n",
    "                    validation_steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot one prediction\n",
    "IMG_ID = 6\n",
    "pathname = 'train/images/img/'\n",
    "list_files = os.listdir(TARGET_FOLDER + pathname)\n",
    "\n",
    "example_image = cv2.imread(TARGET_FOLDER + 'train/images/img/' + list_files[IMG_ID])\n",
    "example_mask = cv2.imread(TARGET_FOLDER + 'train/masks/img/' + list_files[IMG_ID])\n",
    "\n",
    "image_processed = preprocessing_images(example_image)\n",
    "image_processed = tf.expand_dims(image_processed, axis=0)\n",
    "\n",
    "prediction = model.predict(image_processed)\n",
    "pred_image = np.array(tf.squeeze(prediction, axis=0))\n",
    "\n",
    "image_example_gt = np.concatenate((postprocessing_images(example_image),\n",
    "                                   postprocessing_masks_rgb(example_mask),\n",
    "                                   postprocessing_masks_prediction(pred_image)), axis=1)\n",
    "cv2.imshow('Example', image_example_gt) \n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "flatten_image = pred_image.flatten()*256\n",
    "print(max(flatten_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_wise_metrics(y_true, y_pred):\n",
    "  '''\n",
    "  Computes the class-wise IOU and Dice Score.\n",
    "\n",
    "  Args:\n",
    "    y_true (tensor) - ground truth label maps\n",
    "    y_pred (tensor) - predicted label maps\n",
    "  '''\n",
    "  class_wise_iou = []\n",
    "  class_wise_dice_score = []\n",
    "\n",
    "  smoothing_factor = 0.00001\n",
    "\n",
    "  for i in range(n_classes):\n",
    "    intersection = np.sum((y_pred == i) * (y_true == i))\n",
    "    y_true_area = np.sum((y_true == i))\n",
    "    y_pred_area = np.sum((y_pred == i))\n",
    "    combined_area = y_true_area + y_pred_area\n",
    "    \n",
    "    iou = (intersection) / (combined_area - intersection + smoothing_factor)\n",
    "    class_wise_iou.append(iou)\n",
    "    \n",
    "    dice_score =  2 * ((intersection) / (combined_area + smoothing_factor))\n",
    "    class_wise_dice_score.append(dice_score)\n",
    "\n",
    "  return class_wise_iou, class_wise_dice_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4845549733991667]\n",
      "[0.6527949211468906]\n"
     ]
    }
   ],
   "source": [
    "class_wise_iou, class_wise_dice_score = class_wise_metrics(postprocessing_masks_rgb(example_mask), postprocessing_masks_prediction(pred_image))\n",
    "print(class_wise_iou)\n",
    "print(class_wise_dice_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42211440209217366]\n",
      "[0.43285431084171266]\n",
      "[0.5301414036796979]\n",
      "[0.4649568304850543]\n",
      "[0.5404546561228268]\n",
      "[0.44520188739276184]\n",
      "[0.5724852066301075]\n",
      "[0.5380622832937368]\n",
      "[0.33298319298583406]\n",
      "[0.6074218745056789]\n",
      "[0.5878906245215734]\n",
      "[0.5546874995485942]\n",
      "[0.5436466937468606]\n",
      "[0.4586427652935188]\n",
      "[0.4327190099867719]\n",
      "[0.3280196195299207]\n",
      "[0.2769396549237252]\n",
      "[0.4680903894809284]\n",
      "[0.43100734484871694]\n",
      "[0.3211764702733564]\n",
      "[0.4969189051869864]\n",
      "[0.3360080237913674]\n",
      "[0.5670154454683479]\n",
      "[0.4789253138781322]\n",
      "[0.28879753315450707]\n",
      "[0.6665039057075978]\n",
      "[0.6591521680477398]\n",
      "[0.4503874027739837]\n",
      "[0.6299828803864165]\n",
      "[0.4968249932293413]\n",
      "0.4786670897269324\n"
     ]
    }
   ],
   "source": [
    "for (img, mask) in my_val_generator:\n",
    "    \n",
    "    average_iou = 0.\n",
    "    average_dice = 0.\n",
    "    count = 0.\n",
    "    for cur_img, cur_mask in zip(img, mask):\n",
    "        count += 1\n",
    "        \n",
    "        # Compute prediction\n",
    "        tensor_img = np.expand_dims(cur_img, axis=0)\n",
    "        result = model.predict(tensor_img)\n",
    "        \n",
    "        # Compute performance\n",
    "        cls_wise_iou, cls_wise_dice_score = class_wise_metrics(cur_mask, postprocessing_masks_prediction(result[0]))        \n",
    "        \n",
    "        print(cls_wise_iou)\n",
    "        average_iou += cls_wise_iou[0]\n",
    "        average_dice += cls_wise_dice_score[0]\n",
    "    \n",
    "    average_iou = average_iou / count\n",
    "    average_dice = average_dice / count\n",
    "    \n",
    "    break\n",
    "\n",
    "print(average_iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
